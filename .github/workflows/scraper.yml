name: Purse Forum Scraper

on:
  workflow_dispatch:
    inputs:
      keyword:
        description: 'ê²€ìƒ‰ í‚¤ì›Œë“œ'
        required: true
        default: 'rhinoplasty'
      start_page:
        description: 'ì‹œì‘ í˜ì´ì§€'
        required: false
        default: '1'
      max_pages:
        description: 'ìµœëŒ€ í˜ì´ì§€ ìˆ˜'
        required: false
        default: '5'
      max_threads:
        description: 'ìµœëŒ€ ìŠ¤ë ˆë“œ ìˆ˜'
        required: false
        default: '50'
  
  schedule:
    - cron: '0 0 * * *'
  
  push:
    branches: [ main ]

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ ì½”ë“œ ì²´í¬ì•„ì›ƒ
      uses: actions/checkout@v3
    
    - name: ğŸ Python ì„¤ì •
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: ğŸŒ Chrome ì„¤ì¹˜
      uses: browser-actions/setup-chrome@latest
      with:
        chrome-version: stable
    
    - name: ğŸš— ChromeDriver ì„¤ì¹˜
      uses: nanasess/setup-chromedriver@master
    
    - name: ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: ğŸ”‘ êµ¬ê¸€ ì¸ì¦ ì„¤ì •
      run: |
        echo '${{ secrets.GOOGLE_CREDENTIALS }}' > credentials.json
    
    - name: âš™ï¸ ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸
      run: |
        python -c "
        import re
        import os
        
        with open('config.py', 'r', encoding='utf-8') as f:
            content = f.read()
        
        content = content.replace('YOUR_SPREADSHEET_ID_HERE', '${{ secrets.SPREADSHEET_ID }}')
        
        if '${{ github.event_name }}' == 'workflow_dispatch':
            content = re.sub(r'SEARCH_KEYWORD = \".*?\"', 'SEARCH_KEYWORD = \"${{ github.event.inputs.keyword }}\"', content)
            content = re.sub(r'START_PAGE = \d+', 'START_PAGE = ${{ github.event.inputs.start_page }}', content)
            content = re.sub(r'MAX_PAGES = \d+', 'MAX_PAGES = ${{ github.event.inputs.max_pages }}', content)
            content = re.sub(r'MAX_THREADS = \d+', 'MAX_THREADS = ${{ github.event.inputs.max_threads }}', content)
        
        with open('config.py', 'w', encoding='utf-8') as f:
            f.write(content)
        
        print('âœ… config.py ì—…ë°ì´íŠ¸ ì™„ë£Œ!')
        "
    
    - name: ğŸš€ í¬ë¡¤ëŸ¬ ì‹¤í–‰
      run: |
        python scraper.py
    
    - name: ğŸ“‹ ë¡œê·¸ ì—…ë¡œë“œ
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-logs
        path: |
          *.log
          screenshots/